{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import collections\n",
    "import dpkt\n",
    "import socket\n",
    "import os\n",
    "import random\n",
    "import math\n",
    "import numpy as np\n",
    "from scipy.stats import kurtosis, skew\n",
    "from termcolor import colored\n",
    "from joblib import Parallel, delayed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract UDP DATA"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import processing_UDP\n",
    "data_folder = \"/Users/ct/Library/Mobile Documents/com~apple~CloudDocs/cybersecurity_robotics/teleop_data\"\n",
    "# data_class = \n",
    "DEST_IP = '129.97.71.26'\n",
    "SOURCE_IP = '129.97.71.27'\n",
    "processing_UDP.FeatureExtractionCombined(data_folder, DEST_IP, SOURCE_IP, action)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract TCP DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import processing_TCP\n",
    "# data_folder = \"size_defence_action_data/800padded\"\n",
    "# data_folder = \"action_data\"\n",
    "data_folder = \"sawyer_action_data/Position\"\n",
    "dst_folder = \"extractedFeatures/Position\"\n",
    "# DEST_IP = '192.168.1.1'\n",
    "DEST_IP = '192.168.0.100'\n",
    "# SOURCE_IP = '192.168.1.10'\n",
    "SOURCE_IP = '192.168.0.103'\n",
    "all_actions = [d for d in os.listdir(data_folder) if os.path.isdir(os.path.join(data_folder, d))]\n",
    "for action in all_actions:\n",
    "    processing_TCP.FeatureExtractionCombined(data_folder, DEST_IP, SOURCE_IP, dst_folder, action)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EXTRACT TEMPORAL DEPENDENCIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import temp_dep_extractor\n",
    "\n",
    "# data_folder = 'size_defence_action_data/800padded'\n",
    "data_folder = 'action_data'\n",
    "\n",
    "# data_folder = \"action_data\"\n",
    "# Get a list of all directories in the data_folder\n",
    "all_actions = [d for d in os.listdir(data_folder) if os.path.isdir(os.path.join(data_folder, d))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EXTRACT CARTESIAN COMMANDS STATISTICS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = np.array([154, 52, 90, 81, 52, 81, 725, 52, 81, 90, 157, 81, 154])\n",
    "\n",
    "for action_name in all_actions:\n",
    "    extraction_dir = os.path.join('extractedFeatures', action_name, 'cart')\n",
    "    if not os.path.exists(extraction_dir):\n",
    "        os.makedirs(extraction_dir)\n",
    "\n",
    "    dir_path = os.path.join(data_folder, action_name)\n",
    "    files = os.listdir(dir_path)\n",
    "    \n",
    "    for file in files:\n",
    "        if (\".DS_Store\" in file):\n",
    "            continue\n",
    "        print(file)\n",
    "        pcap_file_path = os.path.join(dir_path, file)\n",
    "        timestamps, packet_sizes = temp_dep_extractor.parse_pcap(pcap_file_path)\n",
    "        statistics = temp_dep_extractor.extract_conv_features(timestamps, packet_sizes, file[:-5], action_name, kernel)\n",
    "        df = pd.DataFrame(statistics, index=[0])\n",
    "        \n",
    "        output_file_path = os.path.join(extraction_dir, f'{os.path.splitext(file)[0]}.csv')\n",
    "        df.to_csv(output_file_path, index=False)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EXTRACT GRIPPER SPEED COMMANDS STATISTICS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = np.array([104, 111, 104, 111, 104, 111])\n",
    "\n",
    "for action_name in all_actions:\n",
    "    extraction_dir = os.path.join('extractedFeatures', action_name, 'gripper_speed')\n",
    "    if not os.path.exists(extraction_dir):\n",
    "        os.makedirs(extraction_dir)\n",
    "\n",
    "    dir_path = os.path.join(data_folder, action_name)\n",
    "    files = os.listdir(dir_path)\n",
    "    \n",
    "    for file in files:\n",
    "        if (\".DS_Store\" in file):\n",
    "            continue\n",
    "        print(file)\n",
    "        pcap_file_path = os.path.join(dir_path, file)\n",
    "        timestamps, packet_sizes = temp_dep_extractor.parse_pcap(pcap_file_path)\n",
    "\n",
    "        # Extract features\n",
    "        statistics = temp_dep_extractor.extract_corr_coeff_features(timestamps, packet_sizes, file[:-5], action_name, kernel)\n",
    "        df = pd.DataFrame(statistics, index=[0])\n",
    "        \n",
    "        output_file_path = os.path.join(extraction_dir, f'{os.path.splitext(file)[0]}.csv')\n",
    "        df.to_csv(output_file_path, index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EXTRACT GRIPPER POSITION COMMANDS STATISTICS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = np.array([168,66,104,95,66,104,95,66,104,390,95,104,111,95,66,95,95,66,170])\n",
    "kernel = [x - 14 for x in kernel]\n",
    "\n",
    "for action_name in all_actions:\n",
    "    extraction_dir = os.path.join('extractedFeatures', action_name, 'gripper_position')\n",
    "    if not os.path.exists(extraction_dir):\n",
    "        os.makedirs(extraction_dir)\n",
    "\n",
    "    dir_path = os.path.join(data_folder, action_name)\n",
    "    files = os.listdir(dir_path)\n",
    "    \n",
    "    for file in files:\n",
    "        if (\".DS_Store\" in file):\n",
    "            continue\n",
    "        print(file)\n",
    "        pcap_file_path = os.path.join(dir_path, file)\n",
    "        timestamps, packet_sizes = temp_dep_extractor.parse_pcap(pcap_file_path)\n",
    "        statistics = temp_dep_extractor.extract_conv_features(timestamps, packet_sizes, file[:-5], action_name, kernel)\n",
    "        df = pd.DataFrame(statistics, index=[0])\n",
    "        \n",
    "        output_file_path = os.path.join(extraction_dir, f'{os.path.splitext(file)[0]}.csv')\n",
    "        df.to_csv(output_file_path, index=False)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = temp_dep_extractor.custom_convolve([3,1,2,4,1,3,2,10,12,3,4,4],[2,4,1])\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRAIN CLASSIFIER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python traffic_classifier.py \"/path/to/directory_path\" \"['class1', 'class2']\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
